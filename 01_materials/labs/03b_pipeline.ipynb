{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An initial training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv \n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "ft_dir = os.getenv(\"FEATURES_DATA\")\n",
    "ft_glob = glob(ft_dir+'/*.parquet')\n",
    "df = dd.read_parquet(ft_glob).compute().reset_index().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "+ Previously, we produced a features data set.\n",
    "+ Most times, one or more [preprocessing steps](https://scikit-learn.org/stable/modules/preprocessing.html#) steps will be applied to data.\n",
    "+ The most practical way to apply them is by arranging them in `Pipeline` objects, wchich are sequential transformations applied to data. \n",
    "+ It is convenient for us to label these transformations and there is a standard way of doing so.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "+ Transformations are classes that implement `fit` and `transform` methods.\n",
    "\n",
    "### StandardScaler\n",
    "\n",
    "+ For example, transform a numerical variable by standardizing it.\n",
    "- Standardization is removing the mean value of the feature and scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "$$\n",
    "z = \\frac{x-\\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "\n",
    "+  Using [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), one can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0.771997</td>\n",
       "      <td>0.833191</td>\n",
       "      <td>0.762111</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>512377600.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>-0.084310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0.783293</td>\n",
       "      <td>0.832720</td>\n",
       "      <td>0.775762</td>\n",
       "      <td>0.781411</td>\n",
       "      <td>778321600.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.771997</td>\n",
       "      <td>0.014633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.715509</td>\n",
       "      <td>0.805889</td>\n",
       "      <td>0.715509</td>\n",
       "      <td>0.799299</td>\n",
       "      <td>767972800.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.783293</td>\n",
       "      <td>-0.086538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>0.749401</td>\n",
       "      <td>0.760699</td>\n",
       "      <td>0.719275</td>\n",
       "      <td>0.726806</td>\n",
       "      <td>460734400.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.715509</td>\n",
       "      <td>0.047368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>0.736221</td>\n",
       "      <td>0.770113</td>\n",
       "      <td>0.713626</td>\n",
       "      <td>0.768230</td>\n",
       "      <td>505064000.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.749401</td>\n",
       "      <td>-0.017588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403451</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>407.290009</td>\n",
       "      <td>402.290009</td>\n",
       "      <td>406.040009</td>\n",
       "      <td>270600.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>402.720001</td>\n",
       "      <td>0.007424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403452</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>2025-01-21</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>419.850006</td>\n",
       "      <td>407.619995</td>\n",
       "      <td>407.619995</td>\n",
       "      <td>446000.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>0.030465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403453</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>427.760010</td>\n",
       "      <td>419.589996</td>\n",
       "      <td>425.239990</td>\n",
       "      <td>497500.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>0.005980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403454</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>422.290009</td>\n",
       "      <td>414.450012</td>\n",
       "      <td>417.619995</td>\n",
       "      <td>377100.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403455</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>420.079987</td>\n",
       "      <td>413.739990</td>\n",
       "      <td>419.059998</td>\n",
       "      <td>258900.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>-0.015435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357760 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ticker       Date       Close        High         Low        Open  \\\n",
       "1        AAPL 2000-01-04    0.771997    0.833191    0.762111    0.815304   \n",
       "2        AAPL 2000-01-05    0.783293    0.832720    0.775762    0.781411   \n",
       "3        AAPL 2000-01-06    0.715509    0.805889    0.715509    0.799299   \n",
       "4        AAPL 2000-01-07    0.749401    0.760699    0.719275    0.726806   \n",
       "5        AAPL 2000-01-10    0.736221    0.770113    0.713626    0.768230   \n",
       "...       ...        ...         ...         ...         ...         ...   \n",
       "403451   ZBRA 2025-01-17  405.709991  407.290009  402.290009  406.040009   \n",
       "403452   ZBRA 2025-01-21  418.070007  419.850006  407.619995  407.619995   \n",
       "403453   ZBRA 2025-01-22  420.570007  427.760010  419.589996  425.239990   \n",
       "403454   ZBRA 2025-01-23  421.109985  422.290009  414.450012  417.619995   \n",
       "403455   ZBRA 2025-01-24  414.609985  420.079987  413.739990  419.059998   \n",
       "\n",
       "             Volume  Year  Close_lag_1   Returns  \n",
       "1       512377600.0  2000     0.843077 -0.084310  \n",
       "2       778321600.0  2000     0.771997  0.014633  \n",
       "3       767972800.0  2000     0.783293 -0.086538  \n",
       "4       460734400.0  2000     0.715509  0.047368  \n",
       "5       505064000.0  2000     0.749401 -0.017588  \n",
       "...             ...   ...          ...       ...  \n",
       "403451     270600.0  2025   402.720001  0.007424  \n",
       "403452     446000.0  2025   405.709991  0.030465  \n",
       "403453     497500.0  2025   418.070007  0.005980  \n",
       "403454     377100.0  2025   420.570007  0.001284  \n",
       "403455     258900.0  2025   421.109985 -0.015435  \n",
       "\n",
       "[357760 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>357760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.028180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.518692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.011124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.012434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Returns\n",
       "count  357760.000000\n",
       "mean        0.000849\n",
       "std         0.028180\n",
       "min        -0.518692\n",
       "25%        -0.011124\n",
       "50%         0.000669\n",
       "75%         0.012434\n",
       "max         0.555556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = df[[ 'Returns']].dropna()\n",
    "returns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/_fblas.cpython-39-darwin.so, 0x0002): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: <3701EE70-8E95-3A84-9E0A-F942BAE55AD2> /opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/_fblas.cpython-39-darwin.so\n  Reason: tried: '/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/../../../../liblapack.3.dylib' (no such file), '/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/../../../../liblapack.3.dylib' (no such file), '/opt/miniconda3/envs/dsi_participant/bin/../lib/liblapack.3.dylib' (no such file), '/opt/miniconda3/envs/dsi_participant/bin/../lib/liblapack.3.dylib' (no such file), '/usr/local/lib/liblapack.3.dylib' (no such file), '/usr/lib/liblapack.3.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a StandardScaler object\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      4\u001b[0m std_scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fit the StandardScaler object with the returns data\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/__init__.py:73\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     __check_build,\n\u001b[1;32m     71\u001b[0m     _distributor_init,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m ]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/utils/_chunking.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/sparse/__init__.py:308\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    312\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    313\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/sparse/csgraph/__init__.py:185\u001b[0m\n\u001b[1;32m    157\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected_components\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    160\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaplacian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    161\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsgraph_to_masked\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    183\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegativeCycleError\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_laplacian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shortest_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    187\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[1;32m    188\u001b[0m     NegativeCycleError\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traversal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    191\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    192\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    193\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_pydata_sparse_to_scipy, is_pydata_spmatrix\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/sparse/linalg/__init__.py:129\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dsolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlgmres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/sparse/linalg/_isolve/iterative.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_system\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _NoValue, _deprecate_positional_args\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicgstab\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqmr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/__init__.py:203\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m====================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mLinear algebra (:mod:`scipy.linalg`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_misc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cythonized_array_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/_misc.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinAlgError\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinAlgError\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinAlgWarning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/blas.py:213\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_np\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fblas\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cblas\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/_fblas.cpython-39-darwin.so, 0x0002): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: <3701EE70-8E95-3A84-9E0A-F942BAE55AD2> /opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/_fblas.cpython-39-darwin.so\n  Reason: tried: '/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/../../../../liblapack.3.dylib' (no such file), '/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/scipy/linalg/../../../../liblapack.3.dylib' (no such file), '/opt/miniconda3/envs/dsi_participant/bin/../lib/liblapack.3.dylib' (no such file), '/opt/miniconda3/envs/dsi_participant/bin/../lib/liblapack.3.dylib' (no such file), '/usr/local/lib/liblapack.3.dylib' (no such file), '/usr/lib/liblapack.3.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "# Create a StandardScaler object\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Fit the StandardScaler object with the returns data\n",
    "std_scaler.fit(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the returns data using the fitted scaler\n",
    "\n",
    "scaled_returns_np = std_scaler.transform(returns)\n",
    "scaled_returns = pd.DataFrame(scaled_returns_np, columns=returns.columns)\n",
    "scaled_returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  OneHotEncoder\n",
    "\n",
    "+ Categorical features can be encoded as numerical values using `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sector'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to encode a categorical variable as numerical.\n",
    "+ Important parameters:\n",
    "\n",
    "    - `categories` allows you to specify the categories to work with.\n",
    "    - `drop`: we can drop the `'first'` value (dummy encoding) or `'if_binary'`, a convenience setting for binary values.\n",
    "    - `handle_unknown` allows three options, `'error'`, `'ignore'`, and `'infrequent_if_exist'`, depending on what we want to do with new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder()\n",
    "onehot.fit(df[['sector']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_enc = onehot.transform(df[['sector']])\n",
    "sector_enc.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "+ It is impractical and costly to manipulate data \"by hand\". \n",
    "+ To manage data preprocessing steps within the cross-validation process use `Pipeline` objects.\n",
    "+ A [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) object allows us to sequentially apply transformation steps and, if required, a predictor.\n",
    "+ `Pipeline` objects compose transforms, i.e., classes that implement `transform` and `fit` methods.\n",
    "+ The purpose of `Pipeline` objects is to ensemble transforms and predictors to be used in cross-validation.\n",
    "+ A `Pipeline` is defined by a list of tuples.\n",
    "+ Each tuple is composed of `(\"name\", <ColumnTransformer>)`, the name of the step and the `<ColumnTransformer>` function of our chosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, cohen_kappa_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline(\n",
    "    [\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('knn', DecisionTreeClassifier(criterion = 'entropy', max_depth=3))\n",
    "\n",
    "    ]\n",
    ")\n",
    "pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = df[['sector']]\n",
    "Y0 = df['target']\n",
    "X0_train, X0_test, Y0_train, Y0_test = train_test_split(X0, Y0, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe1.fit(X0_train, Y0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = pipe1.predict(X0_train)\n",
    "Y_pred_test = pipe1.predict(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_poba_train = pipe1.predict_proba(X0_train)\n",
    "Y_proba_test = pipe1.predict_proba(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    'accuracy_score_train': accuracy_score(Y0_train, Y_pred_train),\n",
    "    'accuracy_score_test': accuracy_score(Y0_test, Y_pred_test),\n",
    "    'cohen_kappa_train': cohen_kappa_score(Y0_train, Y_pred_train),\n",
    "    'cohen_kappa_test': cohen_kappa_score(Y0_test, Y_pred_test),\n",
    "    'log_loss_train': log_loss(Y0_train, Y_poba_train),\n",
    "    'log_loss_test': log_loss(Y0_test, Y_proba_test),\n",
    "    'f1_score_train': f1_score(Y0_train, Y_pred_train),\n",
    "    'f1_score_test': f1_score(Y0_test, Y_pred_test)\n",
    "}\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The model does not show great performance, but the pipeline shows results. \n",
    "+ Below, we expand the pipeline to include more variables, and further we will work with more robust model selection pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer\n",
    "\n",
    "+ Use [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to apply transformers to specific columns of a DataFrame.\n",
    "+ In this case, we will scale numeric variables and apply one-hot encoding to categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_transfomer', StandardScaler(), ['returns', 'Volume'] ),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='infrequent_if_exist'), ['sector']), \n",
    "    ], remainder='drop'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('preproc', transformer), \n",
    "        ('decisiontree', DecisionTreeClassifier(criterion = 'entropy', max_depth=3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_transfomer', StandardScaler(), ['returns', 'Volume'] ),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='infrequent_if_exist'), ['sector']), \n",
    "    ], remainder='drop'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('preproc', transformer), \n",
    "        ('decisiontree', DecisionTreeClassifier(criterion = 'entropy', max_depth=3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "The model selection process is an iterative process in which :\n",
    "\n",
    "+ Select schema and load data.\n",
    "+ Define a pipeline and its (hyper) parameters.\n",
    "\n",
    "    - Use ColumnTransformers to transform numeric and cateogrical variables.\n",
    "    - Hyperparameters can be defined independently of code. \n",
    "\n",
    "+ Implement a splitting strategy. \n",
    "\n",
    "    - Use [cross_validate]() to select several metrics and operational details.\n",
    "\n",
    "+ Measure performance.\n",
    "\n",
    "    - [Select metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "\n",
    "+ Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Testing Split\n",
    "\n",
    "+ The first spliting strategy is to use a training, validation, and test set.\n",
    "+ Training set will be used to fit the model.\n",
    "+ Validation set is used to evaluate hyperparameter choice.\n",
    "+ Testing set is used to evaluate performance on data the model has not yet seen.\n",
    "+ In this case we want to compare two models: \n",
    "\n",
    "    - Decision Tree with 3 minumum samples per leaf.\n",
    "    - Decision Tree with 10 minimum samples per leaf.\n",
    "\n",
    "![](./images/03b_train_validate_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters in pipeline steps\n",
    "\n",
    "+ One can obtain the parameters of a pipeline with `pipe.get_params()`.\n",
    "+ We can set any parameter of a pipeline with `pipe.set_parames(**kwargs)`. \n",
    "+ The input `**kwargs` is a dictionary of the params to be modified. Params of the steps are labeled with the name of the step followed by `__` and the name of the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There are a few steps that we will repeat: \n",
    "\n",
    "    - Fit the candidate model on training data.\n",
    "    - Predict on training and test data.\n",
    "    - Compute training and test performance metrics.\n",
    "    - Return.\n",
    "\n",
    "+ We encapsulate this procedure in a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_train, Y_train, X_test, Y_test):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred_train = clf.predict(X_train)\n",
    "    Y_pred_test = clf.predict(X_test)\n",
    "    Y_proba_train = clf.predict_proba(X_train)\n",
    "    Y_proba_test = clf.predict_proba(X_test)\n",
    "    performance_metrics = {\n",
    "        'log_loss_train': log_loss(Y_train, Y_proba_train),\n",
    "        'log_loss_test': log_loss(Y_test, Y_proba_test),\n",
    "        'cohen_kappa_train': cohen_kappa_score(Y_train, Y_pred_train),\n",
    "        'cohen_kappa_test': cohen_kappa_score(Y_test, Y_pred_test),\n",
    "        'f1_score_train': f1_score(Y_train, Y_pred_train),\n",
    "        'f1_score_test': f1_score(Y_test, Y_pred_test),\n",
    "        'accuracy_score_train': accuracy_score(Y_train, Y_pred_train),\n",
    "        'accuracy_score_test': accuracy_score(Y_test, Y_pred_test),\n",
    "    }\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "X = df[['returns', 'Volume', 'sector']]\n",
    "Y = df['target']\n",
    "\n",
    "# Split the data\n",
    "X_rest, X_test, Y_rest, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_validate, Y_train,  Y_validate = train_test_split(X_rest, Y_rest, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate hyperparameter configuration 2\n",
    "pipe_d3 = pipe.set_params(**{'decisiontree__max_depth': 3})\n",
    "res_d3 = evaluate_model(pipe_d3, X_train, Y_train, X_validate, Y_validate)\n",
    "res_d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate hyperparameter configuration 2\n",
    "pipe_d15 = pipe.set_params(**{'decisiontree__max_depth':15})\n",
    "res_d15 = evaluate_model(pipe_d15, X_train, Y_train, X_validate, Y_validate)\n",
    "res_d15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "+ Cross-validation is a resampling method.\n",
    "+ It is an iterative method applied to training data.\n",
    "+ Training data is divided into folds.\n",
    "+ Each fold is used once as a validation set and the rest of the folds are used for training.\n",
    "+ Test data is used for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Scikit's Documentation ](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance), the diagram below shows the data divisions and folds during the cross-validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/03b_grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions that can be used for [calculating cross-validation performance scores](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance): `cross_val_score()` and `cross_validate()`. The first function, [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score), is a convenience function to get quick perfromance calculations. We will discuss `cross_validate()` as it offers advantages over `cross_val_score()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining metrics\n",
    "\n",
    "+ Use [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) to measure one or more performance metrics and operational details.\n",
    "+ There are two advantages of using this function. From [Scikit's documentation](https://scikit-learn.org/stable/modules/cross_validation.html#the-cross-validate-function-and-multiple-metric-evaluation):\n",
    "\n",
    ">- It allows specifying multiple metrics for evaluation.\n",
    ">- It returns a dict containing fit-times, score-times (and optionally training scores, fitted estimators, train-test split indices) in addition to the test score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc', 'neg_log_loss', 'neg_brier_score']\n",
    "d3_dict = cross_validate(pipe_d3, X, Y, cv=5, scoring = scoring, return_train_score = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataFrame form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d3_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d15_dict = cross_validate(pipe_d15, X, Y, cv=5, scoring = scoring, return_train_score = True)\n",
    "pd.DataFrame(d15_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Performance\n",
    "\n",
    "+ Notice that in order to acquire information about our model and continue development, we are spending resources: time, electricity, equipment use, etc. As well, we are generating data and binary objects that implement our models (fitted `Pipeline` objects, for example).\n",
    "+ For certain applications, operating performance (latency or `'score_time'`) may be as important or more important than predictive performance metrics. \n",
    "+ Every experiment throws important information and we can log them, as well as run them systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d15_dict).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
